# Important Definitions

## Intro to Experimental Learning
1. **Make an Observation:** Start by observing something that sparks your curiosity, helping refine a specific question to test, like whether a drug affects headaches or if button color impacts website sales.
2. **Examine the Research:** Review existing research to see if anyone has already answered your question, which might inform your experiment or answer it outright.
3. **Form a Hypothesis:** Develop two hypotheses: the Alternative Hypothesis (your educated guess) and the Null Hypothesis (the opposite). This defines the experiment’s potential outcomes.
4. **Conduct an Experiment:** Test your hypothesis through a well-structured experiment that controls for randomness and external variables, ensuring valid results that reflect the relationship between variables.
5. **Analyze Experimental Results:** Examine the collected data, filter out irrelevant information, and determine if the findings are statistically significant.
6. **Draw Conclusions:** Use the analysis to evaluate if the hypothesis is supported or not. Typically, scientists fail to reject the null hypothesis or reject it, but rarely claim causal relationships outright.

## The Foundation of a Sound Expirement
1. **Control Group/Random Controlled Trials:** A sound experiment includes a control group (no intervention) to compare with the intervention group. Random Controlled Trials (RCTs) ensure unbiased assignment of participants to either group. Double-Blind studies are preferred to eliminate biases from both participants and experimenters.

2. **Appropriate Sampling Techniques and Sample Size:**
- **Independence:** Observations should not influence each other to avoid bias.
- **Random Sampling:** Ensures that each data point has an equal chance of being included, enhancing representativeness.
- **Normal Distribution:** Assumes that repeated sampling will form a bell curve, aiding statistical analysis.
- **Sample Size:** Larger sample sizes reduce randomness and variance, improving the reliability of results.

3. **Reproducibility:** An experiment is reliable if others can reproduce the results by following the same methodology. Reproducibility ensures that findings are not due to chance or hidden variables and confirms the validity of the experiment.

## Other Defintions

### Hypothesis Test
**Importance:** A method to determine if there is enough statistical evidence to reject a null hypothesis in favor of an alternative hypothesis. It helps make data-driven decisions.
- **Example:** A company tests whether a new marketing strategy increases sales. If statistical analysis shows significant improvement, they reject the null hypothesis and implement the strategy.

### Z-Test
**Importance:** A statistical test used to compare population means when the sample size is large (n > 30) and the population variance is known. It helps assess differences between groups.
- **Example:** A researcher tests whether the average IQ of students in a school differs from the national average of 100 using a Z-test.

### T-Test
**Importance**: A statistical test used to compare means of two groups when the sample size is small (n < 30) or population variance is unknown. It evaluates significant differences.
- **Example:** A scientist compares the average weight loss of two diet plans using a t-test to determine if one plan is significantly more effective.

### Two-Tailed Test
**Importance:** A hypothesis test that checks for differences in both directions, meaning extreme values on either side of the distribution can lead to rejecting the null hypothesis.
- **Example:** A company tests if a new product's average rating differs from 4 stars. Both higher and lower ratings could reject the null hypothesis.

### Left-Tailed Test
**Importance:** A hypothesis test that checks if a parameter is significantly less than a given value. It focuses only on the lower tail of the distribution.
- **Example:** A manufacturer tests if a machine produces fewer than 500 units per hour. If the test statistic falls in the left tail, they may adjust the machine.

### Right-Tailed Test
**Importance:** A hypothesis test that checks if a parameter is significantly greater than a given value. It focuses only on the upper tail of the distribution.
- **Example:** A professor tests if students score significantly higher than 75 on an exam. If the test statistic is in the right tail, the null hypothesis is rejected.

### Null Hypothesis
**Importance:** A statistical assumption stating no effect or difference exists in a population. It serves as the default claim, tested against alternative hypotheses to determine statistical significance in research.
- **Example**: In a drug effectiveness study, the null hypothesis (H₀) might be "The new drug has no effect on blood pressure compared to a placebo." If statistical analysis shows a low p-value (e.g., < 0.05), researchers may reject H₀ and conclude the drug is effective.


### Experimental Design
**Importance:** The process of planning a study to ensure valid, reliable, and unbiased results. It defines variables, controls confounding factors, and determines how data will be collected and analyzed.
- **Example:** A pharmaceutical company designs a double-blind experiment to test a new drug, ensuring neither patients nor researchers know who receives the treatment or placebo.

### Effect Size
**Importance:** Measures the magnitude of a difference between groups, indicating practical significance beyond p-values. Larger effect sizes suggest stronger relationships or differences.
- **Example:** A study finds a new teaching method improves test scores by an average of 15 points, representing a large effect size with real-world importance.

### One and Two Sample T-Tests
**Importance:** Statistical tests comparing means; a one-sample t-test compares a sample mean to a known value, while a two-sample t-test compares means of two independent groups.
- **Example:** A one-sample t-test checks if a factory’s output differs from 100 units per day; a two-sample t-test compares average salaries between two companies.

### Type 1 and Type 2 Errors
**Importance:** Type 1 error (false positive) occurs when a true null hypothesis is rejected; Type 2 error (false negative) occurs when a false null hypothesis is not rejected.
- **Example:** A Type 1 error happens if a court wrongly convicts an innocent person, while a Type 2 error happens if a guilty person is acquitted.

## Other Defintions
### P-Value
**Importance:** The probability of obtaining results as extreme as the observed ones, assuming the null hypothesis is true. A smaller p-value suggests stronger evidence against the null hypothesis.
- **Example:** A p-value of 0.03 in a drug trial suggests only a 3% chance the observed effect is due to random variation, so researchers may conclude the drug is effective.

### T-Value
**Importance:** The test statistic in a t-test that measures how far the sample mean deviates from the population mean in terms of standard error. A larger absolute t-value indicates a greater difference between groups.
- **Example:** In a study comparing test scores of two teaching methods, a t-value of 2.5 suggests the observed difference is 2.5 times the standard error, helping determine if the difference is statistically significant.

### T-Distribution
**Importance:** A probability distribution used in hypothesis testing when the sample size is small, and the population standard deviation is unknown. It accounts for increased variability in smaller samples.
- **Example:** When testing whether a new study technique improves exam scores with a sample of 15 students, the t-distribution is used instead of the normal distribution to calculate confidence intervals and p-values.

### Sigma (σ)
**Importance:** A measure of standard deviation in a population, representing data spread around the mean. Larger sigma values indicate greater variability, while smaller values suggest tightly clustered data points.
- **Example:** If a factory's machine produces screws with a diameter of 10mm and σ = 0.1mm, quality control can ensure deviations remain within acceptable limits.

### Z-Score
**Importance:** A standardized score indicating how many standard deviations a data point is from the mean. Positive values are above the mean; negative values are below the mean.
- **Example:** A student's test score of 85 with a mean of 75 and σ = 5 has a Z-score of 2, meaning the score is 2 standard deviations above average.

### Critical Region
**Importance:** The set of values in a statistical test where, if the test statistic falls within this region, the null hypothesis is rejected. Its size depends on the chosen significance level.
- **Example:** In a clinical study, if a test statistic falls within the critical region (e.g., beyond ±1.96 for a 95% confidence level), the new treatment is considered significantly different.

### Alpha (α)
**Importance:** The probability of rejecting the null hypothesis when it is actually true, also known as the significance level. Common values are 0.05 or 0.01, indicating acceptable error rates.
- **Example:** If α = 0.05 in an A/B test for a website change, there’s a 5% risk of falsely concluding the new design improves user engagement when it actually doesn’t.
